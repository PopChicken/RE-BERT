{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB-cgVUUSmNl"
      },
      "source": [
        "# 克隆仓库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YBmt7OX0PSix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42df51c-3f03-46c3-9f3d-8ae19fe01ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RE-BERT'...\n",
            "remote: Enumerating objects: 106, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 106 (delta 13), reused 11 (delta 11), pack-reused 86\u001b[K\n",
            "Receiving objects: 100% (106/106), 1.87 MiB | 25.94 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/adailtonaraujo/RE-BERT\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-xvtmoWq6jw",
        "outputId": "c6ea54cc-261e-4b2c-a751-76e455f1223b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/RE-BERT\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "# 更新仓库\n",
        "%cd RE-BERT\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7F24wi-bXEG"
      },
      "source": [
        "# 下载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bakFmMM2JGR3",
        "outputId": "c35a7625-a258-4082-f1cc-ef6dded34fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-5v7gCPWaKKBtJVu0KZwvlDyEia40crr\n",
            "To: /content/RE-BERT/demo_api_8apps_v1.model\n",
            "100% 455M/455M [00:05<00:00, 88.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1-5v7gCPWaKKBtJVu0KZwvlDyEia40crr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwDbUl_4mK67"
      },
      "source": [
        "# 安装依赖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TriRyWUlW650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7a995a2-d719-47cc-fef6-a696a82d0b26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.21.6)\n",
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.11.0+cu113)\n",
            "Collecting transformers==2.3.0\n",
            "  Downloading transformers-2.3.0-py3-none-any.whl (447 kB)\n",
            "\u001b[K     |████████████████████████████████| 447 kB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (0.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.3.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.24.7-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 49.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.0->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirements.txt (line 4)) (1.0.2)\n",
            "Collecting botocore<1.28.0,>=1.27.7\n",
            "  Downloading botocore-1.27.7-py3-none-any.whl (8.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.9 MB 53.3 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.7->boto3->transformers==2.3.0->-r requirements.txt (line 3)) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.7->boto3->transformers==2.3.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 74.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.3.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.3.0->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirements.txt (line 4)) (1.4.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=2c0d180c4e83bc45a6b7fd10cae06131054becbf73fa625df1d8e016861b1287\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.7 botocore-1.27.7 jmespath-1.0.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 transformers-2.3.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c27WbNtJaL6_"
      },
      "source": [
        "# 加载模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wam3PqGvVzpt",
        "outputId": "bd7ddeea-31ef-4ddd-e75c-feeb92237c6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model RE_BERT ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from re_bert_demo import re_bert_model\n",
        "from re_bert_demo import extract\n",
        "import numpy as np\n",
        "\n",
        "options = ['--classifier_model_file','demo_api_8apps_v1.model']\n",
        "model = re_bert_model(options)  # 加载模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eIA72_-onEU"
      },
      "source": [
        "# 用例1\n",
        "\n",
        "> I use the app to apply filters to my photos and it's really fun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vwk_jjopk8xT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea4b054-cfb7-4060-f35e-477393b492b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rExtract software requirements candidates:   0%|          | 0/1 [00:00<?, ?it/s]/content/RE-BERT/re_bert_demo.py:73: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100%|██████████| 1/1 [00:00<00:00,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Review:  I use the app to apply filters to my photos and it's really fun.\n",
            "Software Requirements Extracted (in each sentence): ['filters;my photos']\n",
            "\n",
            "\n",
            "Sentence: I use the app to apply filters to my photos and it's really fun.\n",
            "Software Requirements Tokens: ['filters', 'my', 'photos']\n",
            "Token [ I ] is tag [ O ] with 0.9931491 confidence.\n",
            "Token [ use ] is tag [ O ] with 0.99655616 confidence.\n",
            "Token [ the ] is tag [ O ] with 0.9950093 confidence.\n",
            "Token [ app ] is tag [ O ] with 0.99786866 confidence.\n",
            "Token [ to ] is tag [ O ] with 0.98195285 confidence.\n",
            "Token [ apply ] is tag [ O ] with 0.99565744 confidence.\n",
            "Token [ filters ] is tag [ B ] with 0.9494474 confidence.\n",
            "Token [ to ] is tag [ O ] with 0.98195285 confidence.\n",
            "Token [ my ] is tag [ I ] with 0.87882715 confidence.\n",
            "Token [ photos ] is tag [ I ] with 0.9809651 confidence.\n",
            "Token [ and ] is tag [ O ] with 0.9959637 confidence.\n",
            "Token [ it ] is tag [ O ] with 0.9980205 confidence.\n",
            "Token [ 's ] is tag [ O ] with 0.9980354 confidence.\n",
            "Token [ really ] is tag [ O ] with 0.9996358 confidence.\n",
            "Token [ fun ] is tag [ O ] with 0.99950397 confidence.\n",
            "Token [ . ] is tag [ O ] with 0.99938476 confidence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "review = \"I use the app to apply filters to my photos and it's really fun.\"\n",
        "predictions,requirements_extracted = extract(model,review)\n",
        "\n",
        "\n",
        "print('\\n\\nReview: ',review)\n",
        "print('Software Requirements Extracted (in each sentence):',requirements_extracted)\n",
        "\n",
        "for item in predictions:\n",
        "  sentence = item[0]\n",
        "  software_requirements = item[1]\n",
        "  iob_classification = item[2]\n",
        "  print('\\n\\nSentence:',sentence)\n",
        "  print('Software Requirements Tokens:',software_requirements)\n",
        "  for tokens_res in iob_classification:\n",
        "    token = tokens_res[0]\n",
        "    confidence = np.max(tokens_res[1]['confidences'])\n",
        "    iob_class = np.max(tokens_res[1]['iob'])\n",
        "    iob_tag = 'O'\n",
        "    if iob_class == 0: iob_tag='B'\n",
        "    if iob_class == 1: iob_tag='I'\n",
        "    print('Token [',token,'] is tag [',iob_tag,'] with',confidence,'confidence.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s6Clg3eoxm2"
      },
      "source": [
        "# 用例2\n",
        "\n",
        "> I am trying to set up a business account and change my email address and I am having the most difficulty using your app its totally ridiculous! And another thing I am unable to see prices until driver has been found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "MHRVTWE8nzLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c30a1ac0-d49c-42b5-d525-cac39a24356b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extract software requirements candidates: 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Review:  I am trying to set up a business account and change my email address and I am having the most difficulty using your app its totally ridiculous! And another thing I am unable to see prices until driver has been found.\n",
            "Software Requirements Extracted (in each sentence): ['up;business account;change my email address', 'see prices']\n",
            "\n",
            "\n",
            "Sentence: I am trying to set up a business account and change my email address and I am having the most difficulty using your app its totally ridiculous!\n",
            "Software Requirements Tokens: ['up', 'business', 'account', 'change', 'my', 'email', 'address']\n",
            "Token [ I ] is tag [ O ] with 0.93952286 confidence.\n",
            "Token [ am ] is tag [ O ] with 0.9886057 confidence.\n",
            "Token [ trying ] is tag [ O ] with 0.99090403 confidence.\n",
            "Token [ to ] is tag [ O ] with 0.9771086 confidence.\n",
            "Token [ set ] is tag [ O ] with 0.65294075 confidence.\n",
            "Token [ up ] is tag [ I ] with 0.7320299 confidence.\n",
            "Token [ a ] is tag [ O ] with 0.85553056 confidence.\n",
            "Token [ business ] is tag [ I ] with 0.9410975 confidence.\n",
            "Token [ account ] is tag [ I ] with 0.9938638 confidence.\n",
            "Token [ and ] is tag [ O ] with 0.803055 confidence.\n",
            "Token [ change ] is tag [ I ] with 0.542482 confidence.\n",
            "Token [ my ] is tag [ I ] with 0.9591564 confidence.\n",
            "Token [ email ] is tag [ I ] with 0.6736888 confidence.\n",
            "Token [ address ] is tag [ I ] with 0.9640887 confidence.\n",
            "Token [ and ] is tag [ O ] with 0.803055 confidence.\n",
            "Token [ I ] is tag [ O ] with 0.93952286 confidence.\n",
            "Token [ am ] is tag [ O ] with 0.9886057 confidence.\n",
            "Token [ having ] is tag [ O ] with 0.9926077 confidence.\n",
            "Token [ the ] is tag [ O ] with 0.938386 confidence.\n",
            "Token [ most ] is tag [ O ] with 0.9945322 confidence.\n",
            "Token [ difficulty ] is tag [ O ] with 0.9954059 confidence.\n",
            "Token [ using ] is tag [ O ] with 0.99673045 confidence.\n",
            "Token [ your ] is tag [ O ] with 0.89347434 confidence.\n",
            "Token [ app ] is tag [ O ] with 0.99781525 confidence.\n",
            "Token [ its ] is tag [ O ] with 0.99531674 confidence.\n",
            "Token [ totally ] is tag [ O ] with 0.99497753 confidence.\n",
            "Token [ ridiculous ] is tag [ O ] with 0.9966168 confidence.\n",
            "Token [ ! ] is tag [ O ] with 0.9971118 confidence.\n",
            "\n",
            "\n",
            "Sentence: And another thing I am unable to see prices until driver has been found.\n",
            "Software Requirements Tokens: ['see', 'prices']\n",
            "Token [ And ] is tag [ O ] with 0.9988279 confidence.\n",
            "Token [ another ] is tag [ O ] with 0.99792 confidence.\n",
            "Token [ thing ] is tag [ O ] with 0.9991015 confidence.\n",
            "Token [ I ] is tag [ O ] with 0.99924576 confidence.\n",
            "Token [ am ] is tag [ O ] with 0.9988047 confidence.\n",
            "Token [ unable ] is tag [ O ] with 0.9962655 confidence.\n",
            "Token [ to ] is tag [ O ] with 0.9954561 confidence.\n",
            "Token [ see ] is tag [ B ] with 0.86818695 confidence.\n",
            "Token [ prices ] is tag [ I ] with 0.9801446 confidence.\n",
            "Token [ until ] is tag [ O ] with 0.99432385 confidence.\n",
            "Token [ driver ] is tag [ O ] with 0.99550974 confidence.\n",
            "Token [ has ] is tag [ O ] with 0.99833375 confidence.\n",
            "Token [ been ] is tag [ O ] with 0.99855405 confidence.\n",
            "Token [ found ] is tag [ O ] with 0.9975466 confidence.\n",
            "Token [ . ] is tag [ O ] with 0.99818784 confidence.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "review = \"I am trying to set up a business account and change my email address and I am having the most difficulty using your app its totally ridiculous! And another thing I am unable to see prices until driver has been found.\"\n",
        "predictions,requirements_extracted = extract(model,review)\n",
        "\n",
        "\n",
        "print('\\n\\nReview: ',review)\n",
        "print('Software Requirements Extracted (in each sentence):',requirements_extracted)\n",
        "\n",
        "for item in predictions:\n",
        "  sentence = item[0]\n",
        "  software_requirements = item[1]\n",
        "  iob_classification = item[2]\n",
        "  print('\\n\\nSentence:',sentence)\n",
        "  print('Software Requirements Tokens:',software_requirements)\n",
        "  for tokens_res in iob_classification:\n",
        "    token = tokens_res[0]\n",
        "    confidence = np.max(tokens_res[1]['confidences'])\n",
        "    iob_class = np.max(tokens_res[1]['iob'])\n",
        "    iob_tag = 'O'\n",
        "    if iob_class == 0: iob_tag='B'\n",
        "    if iob_class == 1: iob_tag='I'\n",
        "    print('Token [',token,'] is tag [',iob_tag,'] with',confidence,'confidence.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fNiuqeXq6jy"
      },
      "source": [
        "# 模型评估\n",
        "\n",
        "**生成标注文件**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "APPNAME = 'Twitter'"
      ],
      "metadata": {
        "id": "oMwrzjP_tbjF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_eCnNPEq6jz",
        "outputId": "c1580d19-678b-44a7-c66e-55950b2dc915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "loading model RE_BERT ...\n",
            "Test Size: 183\n",
            "Extract software requirements candidates:   0% 0/183 [00:00<?, ?it/s]extract.py:72: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
            "  t_inputs = [torch.tensor([data[col]], device=self.opt.device) for col in self.opt.inputs_cols]\n",
            "Extract software requirements candidates: 100% 183/183 [00:43<00:00,  4.25it/s]\n",
            "Extracted software requirements --> Twitter_extracted_reqs.txt\n"
          ]
        }
      ],
      "source": [
        "!python extract.py --test_file datasets_iob/test_data_{APPNAME}.txt --classifier_model_file demo_api_8apps_v1.model --output_file {APPNAME}_extracted_reqs.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2RNjgVMq6jz"
      },
      "source": [
        "**与人工标注比对**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7BnSGbcqq6jz"
      },
      "outputs": [],
      "source": [
        "reviews_test = open(f'datasets_iob/test_data_{APPNAME}.txt', 'r').readlines()\n",
        "reqs_exracted =  open(f'{APPNAME}_extracted_reqs.txt', 'r').readlines()\n",
        "reqs_labeled =  open(f'datasets_iob/test_label_{APPNAME}.txt', 'r').readlines()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluation\n",
        "\n",
        "\n",
        "eva = evaluation.f1_measure(reqs_exracted, reqs_labeled, min(len(reqs_exracted), len(reqs_labeled)))\n",
        "print(f'准确率: {eva[0]}; 召回率: {eva[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9HVNukW4cuA",
        "outputId": "24e8d6e2-e748-4424-8ecd-dcc9c1d22f2a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "准确度: 0.7846153846153846; 召回率: 0.85.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lzGGSoBq6jz",
        "outputId": "9e11a3ae-c76e-4e7f-be2c-d7b57a39c086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.644808743169399\n"
          ]
        }
      ],
      "source": [
        "# 使用pandas进行简单对比\n",
        "import pandas as pd\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "df = pd.DataFrame()\n",
        "df['review'] = reviews_test\n",
        "df['labeled (humans)'] = reqs_labeled\n",
        "df['extracted (re-bert)'] = reqs_exracted\n",
        "df = df.replace('\\n',' ', regex=True)\n",
        "total = len(df)\n",
        "hit = len(df[df['labeled (humans)'] == df['extracted (re-bert)']])\n",
        "print(f'accuracy: {hit / total}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Pre-trained RE-BERT Model - API Demo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit ('3.10.0')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "0838e1853ac9b69cd2ebaa278a6b4e341d1ca5c2a73e9e479b20533bfa70ed2b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}